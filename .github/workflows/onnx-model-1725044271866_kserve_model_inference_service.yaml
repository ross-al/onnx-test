apiVersion: serving.kserve.io/v1beta1
kind: "InferenceService"
metadata:
  name: "onnx-model-1725044271866"
  namespace: "onnx-model-1725044271866"
spec:
  predictor:
    onnx: #Todo make abstract and inject based on model manager
      storageUri: "s3://mlflow-lite-bucket/mlflow-artifacts/29/b5893a1972bc4622b1fd69cb7a526f8f/artifacts/model"
    minReplicas: 1
    maxReplicas: 1


# # Old schema 

# apiVersion: "serving.kserve.io/v1beta1"
# kind: "InferenceService"
# metadata:
#   name: "style-sample"
# spec:
#   predictor:
#     onnx:
#       storageUri: "gs://kfserving-examples/models/onnx"


# # New schema 

# apiVersion: serving.kserve.io/v1beta1
# kind: "InferenceService"
# metadata:
#   name: "onnx-model-1725044271866"
#   namespace: "onnx-model-1725044271866"
# spec:
#   predictor:
#     model:
#       protocolVersion: v2 # Must explicitly state protocol with new schema
#       modelFormat:
#         name: "onnx"
#       storageUri: "s3://mlflow-lite-bucket/mlflow-artifacts/29/b5893a1972bc4622b1fd69cb7a526f8f/artifacts/model"
#     minReplicas: 1
#     maxReplicas: 1